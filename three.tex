\documentclass[11pt]{report}%% or 10pt, or 12pt

\begin{document}
\chapter{introduction}

\textbf{motivation , primarily problem to solve}\newline
we need jobs to match skills we need to detect skills\newline
\textbf{real motivation secondary problem that we are actually solving}\newline
how to detect skills. why it is challenging and different than usual keyword extraction problems 

\chapter{literature review}
\section{what are the algorithms in keyword extraction }
\textbf{NLP introduction} 
The automatic analysis of 

text involves a deep understanding of 

natural language by machines, a reality 

from which we are still very far off \cite{review on NLP}.
Hitherto, online information 

retrieval, aggregation, and processing 

have mainly been based on algorithms 

relying on the textual representation of 

web pages. Such algorithms are very 

good at retrieving texts, splitting them 

into parts, checking the spelling and 

counting the number of words. When 

it comes to interpreting sentences and 

extracting meaningful information, however, their capabilities are known to 

be very limited. NLp in fact, requires high level symbolic capabilities(Dyer 1994) including:

1-creation and propagation of dynamic 

bindings;
2-manipulation of recursive, constituent structures,
 acquisition and access of lexical, semantic, and episodic memories;
❏ control of multiple learning/process- ing modules and routing of informa- tion among such modules;
❏ grounding of basic-level language constructs (e.g., objects and actions) in perceptual/motor experiences;
❏ representation of abstract concepts.
All such capabilities are required to shift from mere NLP to what is usually referred to as natural language under- standing (Allen, 1987). Today, most of the existing approaches are still based on the syntactic representation of text, a method that relies mainly on word co- occurrence frequencies. Such algorithms are limited by the fact that they can pro- cess only the information that they can ‘see’. As human text processors, we do not have such limitations as every word we see activates a cascade of semantically related concepts, relevant episodes, and sensory experiences, all of which enable the completion of complex NLP tasks—such as word-sense disam- biguation, textual entailment, and semantic role labeling—in a quick and
effortless way.

\textbf{supervised} \newline
\textbf{unsupervised}\newline
\textbf{graph-based algorithms}\newline
\textbf{what works and what fails}\newline
\section {Automatic keyphrase extraction}
\textbf{what does it mean to tag data by people}
Tagging is the process of labeling web resources based on their content. Each label, or tag, corre- sponds to a topic in a given document. Unlike metadata assigned by authors, or by professional indexers in libraries, tags are assigned by end- users for organizing and sharing information that is of interest to them. The organic system of tags assigned by all users of a given web platform is called a folksonomy.\cite{folksonomy}


\chapter{our approach our algorithm}
\textbf{our algorithm a bit of introduction}\newline
\textbf{data acquisition}\newline
\textbf{data cleaning}\newline
\textbf{the results}\newline

\chapter{visualization of trends}

\chapter{conclusion}

%\begin{thebibliography}{1}
%\bibitem[1]{review on NLP}Cambria, E., \& White, B. (2014). Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]. IEEE Computational %Intelligence Magazine, 9(2), 48–57. doi:10.1109/MCI.2014.
%\bibitem[2]{folksonomy}
%\end{thebibliography}
%\bibliographystyle{plain}
%\bibliography{both_thes}

\end{document}
